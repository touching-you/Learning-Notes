### Spark 累加器

Spark累加器（accumulator）是一种分布式计算中的共享变量，用于在多个节点上累加信息。它们通常用于计数器和求和等场景。Spark累加器的主要特点是可以在不同节点上同时更新，同时具有容错机制，即使某些节点崩溃或失败，也能保证正确的结果。

Spark累加器有两种类型：数值型累加器和自定义累加器。

1. 数值型累加器：数值型累加器是Spark提供的一种默认的累加器类型，它支持整数和浮点数类型的累加操作。使用数值型累加器时，每个节点上的值可以简单地加到累加器的总和中，而不需要考虑并发访问的问题。
2. 自定义累加器：自定义累加器是一种用户自己定义的累加器类型，它可以支持任何类型的累加操作。要**创建一个自定义累加器，需要实现AccumulatorV2抽象类，并实现其中的两个方法：update()和merge()**。u**pdate()方法用于将一个值累加到累加器中**，而**merge()方法则用于将两个累加器合并为一个**。自定义累加器可以用于更复杂的累加操作，例如字符串拼接或对象合并等。

无论是数值型累加器还是自定义累加器，都可以通过SparkContext的accumulator()方法来创建，并通过调用value属性来访问累加器的值。在Spark程序中，累加器通常用于统计计数、计算平均值或检查数据集中的异常值等任务。

### Spark 广播器

Spark广播器（Broadcast）是一种用于在Spark集群中共享大型只读变量的机制。在分布式计算中，数据传输是一个瓶颈，因此在多个节点上广播一个只读的变量，可以避免数据传输的瓶颈，提高程序的性能。

Spark广播器的主要特点是，它**可以将变量缓存在每个节点的内存中，并在任务执行时在节点本地访问该变量，避免了数据的多次传输**。Spark广播器的使用场景通常是，某个变量在任务执行过程中不变，但在所有任务中都需要使用该变量的值。

在Spark中，广播器可以使用SparkContext的broadcast()方法创建。广播变量可以是任何类型的对象，例如集合、Map或自定义对象等。使用广播变量时，可以通过调用value属性来访问广播变量的值。在任务执行期间，Spark会自动将广播变量分发到各个节点，并在节点本地使用该变量，而不是多次传输变量的值。

总的来说，Spark广播器是一种非常有用的工具，可以在Spark集群中共享大型只读变量，提高程序的性能。但是需要注意的是，广播变量的创建和使用需要谨慎，如果广播的变量过大，可能会占用过多的内存，导致程序崩溃。因此，在使用广播变量时，需要仔细考虑广播变量的大小和使用场景，以确保程序的正确性和高效性。