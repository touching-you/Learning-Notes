#### InputFormat数据输入

切片与MapTask并行度决定机制

**数据切片**：数据切片只是在逻辑上对输入进行分片（**逻辑切片**），并不会在磁盘上将其切分成片进行存储。

**并行度决定**：数据切片是MapReduce程序计算输入数据的单位，**一个切片会对应启动一个MapTask**。（默认情况下切片大小==块大小；**切片针对文件，而非数据整体**）

**MapReduce**详细的工作流程

> <img src="G:\编程学习\大数据学习\Hadoop\HDFS\images\wps1.png" alt="img" style="zoom:80%;" />

#### Shuffle

在 MapReduce 中，Shuffle 过程是将 Map 函数生成的中间键值对按照键值进行排序和重分配的过程。Shuffle 过程的主要目的是将具有相同键的值收集到同一个 Reduce 函数进行处理。

Shuffle 过程包括以下步骤：

1. **Partitioning（分区）**：在 Map 阶段生成的键值对将根据键进行分区，以确保相同键的键值对被分配到同一个 Reduce 函数进行处理。Partitioning 过程的输出是一个键值对列表，其中键是分区的 ID，值是分区中的所有键值对。

2. **Sorting（排序）**：Partitioning 后，每个分区内的键值对根据键进行排序。MapReduce 框架默认使用快速排序算法进行排序。

3. **Combining（合并）**：如果启用了 Combine 函数，则在 Sorting 过程中，每个分区内具有相同键的键值对将被合并。这减少了数据传输和 Reduce 函数的负载，从而提高了性能。

4. **Shuffling（重分配）**：在 Sorting 和 Combining 完成后，框架将根据 Reduce 函数的数量将键值对重分配到对应的 Reduce 函数所在的节点上。

   > 在 MapReduce 中，确定分区和 Reduce 函数的数量通常是一项重要的决策，这直接影响了 MapReduce 作业的性能。
   >
   > 对于**分区数量**，**通常应根据输入数据大小和集群配置进行决策**。如果分区数量过少，可能会导致某些 Reduce 函数负载过大，而其他 Reduce 函数的负载过轻。这会影响整个作业的性能。如果分区数量过多，则会增加 Reduce 函数之间的通信和管理开销，这也会影响整个作业的性能。一般而言，可以根据输入数据大小和集群配置，选择分区数量为总核数的1.5倍到2倍左右，以获得较好的性能。
   >
   > 对于 **Reduce 函数的数量**，**可以根据数据处理的负载和集群配置进行决策**。如果 Reduce 函数数量过少，可能会导致某些 Reduce 函数负载过大，从而降低作业的性能。如果 Reduce 函数数量过多，可能会增加网络传输和管理开销，降低作业的性能。通常，可以根据经验或试验来确定最佳的 Reduce 函数数量。如果不确定最佳数量，可以先选择较多的数量，然后根据作业的运行情况和性能，调整 Reduce 函数数量。
   >
   > 需要注意的是，分区和 Reduce 函数的数量是可以在作业运行时进行调整的。如果在作业运行时发现某些 Reduce 函数负载过大或过轻，可以通过增加或减少 Reduce 函数的数量来重新分配负载，以获得更好的性能。

#### OutputFormat

